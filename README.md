# Bias Detection in AI-Generated Text

A comprehensive system for detecting and analyzing various types of bias (gender, racial, political, religious, socioeconomic) in text generated by language models.

## ğŸ¯ Project Overview

This project develops an automated framework for detecting and quantifying multiple dimensions of bias in text generated by large language models. It addresses the lack of comprehensive, scalable methods to evaluate bias across different prompting strategies and model architectures.

### Key Features

- âœ… Multi-category bias detection (gender, race, religion, political, socioeconomic, age)
- âœ… Real-time text analysis with visual highlighting
- âœ… Lexicon-based and transformer-based detection methods
- âœ… Quantitative bias metrics and severity scoring
- âœ… Interactive web interface
- âœ… RESTful API for integration
- âœ… Comprehensive analysis reports

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ â† React + Vite + TailwindCSS
â”‚   (Port 5173)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend API   â”‚ â† FastAPI + Python
â”‚   (Port 8000)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bias Detection  â”‚ â† Lexicon + Transformers
â”‚     Models      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset

Using **BEADs (Bias Evaluation Across Domains)** - a modern, comprehensive benchmark for evaluating bias in LLMs:
- Multiple bias categories
- Multiple NLP tasks
- Intersectional analysis support
- Publicly available on Hugging Face

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 18+
- pip and npm

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd bias-detection-system
```

2. **Backend Setup**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python -c "import nltk; nltk.download('punkt')"
```

3. **Frontend Setup**
```bash
cd ../frontend
npm install
```

### Running the Application

1. **Start Backend** (Terminal 1)
```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

2. **Start Frontend** (Terminal 2)
```bash
cd frontend
npm run dev
```

3. **Access the Application**
- Frontend: http://localhost:5173
- Backend API Docs: http://localhost:8000/docs

## ğŸ“ Project Structure

```
bias-detection-system/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI application
â”‚   â”‚   â”œâ”€â”€ models/            # Bias detection models
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â”œâ”€â”€ utils/             # Utilities
â”‚   â”‚   â””â”€â”€ data/              # Lexicons and data
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ services/          # API client
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ dataset_exploration.ipynb
â”‚   â””â”€â”€ model_training.ipynb
â”‚
â”œâ”€â”€ data/                      # Data storage
â”‚   â”œâ”€â”€ raw/                   # Raw datasets
â”‚   â”œâ”€â”€ processed/             # Processed data
â”‚   â””â”€â”€ results/               # Analysis results
â”‚
â””â”€â”€ README.md
```

## ğŸ”¬ Methodology

### 1. Data Collection
- Using BEADs dataset from Hugging Face
- Generating additional samples from open-source LLMs
- Diverse demographic scenarios

### 2. Detection Methods

#### Lexicon-Based
- Pattern matching with curated bias lexicons
- Context-aware term detection
- Severity scoring

#### Transformer-Based (Future)
- Fine-tuned BERT/RoBERTa classifiers
- Trained on BEADs and related datasets
- Multi-label classification

### 3. Metrics
- Bias severity (mild, moderate, severe)
- Category-specific scores
- Overall bias score
- Precision, recall, F1

### 4. Evaluation
- Benchmark comparisons
- Human annotation validation
- Cross-model analysis

## ğŸ“ Team & Assignments

| Team Member | Role | Responsibilities |
|-------------|------|------------------|
| **Abdula Ameen** | Backend Lead | API development, model integration, dataset processing, evaluation pipelines |
| **Ali Zahr** | Frontend Lead | UI/UX design, React components, frontend-backend integration |
| **Chance Inosencio** | ML Engineer | Model training, fine-tuning, evaluation metrics, bias analysis |
| **Ghina Albabbili** | Documentation | Written report, visualizations, presentation, analysis coordination |

## ğŸ“ˆ Progress

- [x] GitHub repository initialized
- [x] Backend infrastructure setup
- [x] Frontend infrastructure setup
- [x] BEADs dataset integration
- [x] Lexicon-based detection implemented
- [x] API endpoints created
- [x] Interactive UI developed
- [ ] Transformer model fine-tuning
- [ ] Comprehensive evaluation
- [ ] Human validation study
- [ ] Final report and presentation

## ğŸ”§ API Usage

### Detect Bias
```bash
curl -X POST "http://localhost:8000/api/v1/detect" \
  -H "Content-Type: application/json" \
  -d '{"text": "The female nurse assisted the male doctor."}'
```

### Comprehensive Analysis
```bash
curl -X POST "http://localhost:8000/api/v1/analyze" \
  -H "Content-Type: application/json" \
  -d '{"text": "Your text here"}'
```

## ğŸ“Š Bias Categories

| Category | Description | Examples |
|----------|-------------|----------|
| **Gender** | Gender stereotypes and imbalances | Occupation stereotypes, pronoun bias |
| **Race** | Racial and ethnic bias | Stereotypical associations, discriminatory language |
| **Religion** | Religious bias and stereotypes | Extremism associations, prejudicial terms |
| **Political** | Political bias and loaded language | Partisan terms, inflammatory rhetoric |
| **Socioeconomic** | Class-based stereotypes | Wealth assumptions, status bias |
| **Age** | Age-related bias | Ageism, generational stereotypes |

## ğŸ§ª Testing

### Backend Tests
```bash
cd backend
pytest
```

### Frontend Tests
```bash
cd frontend
npm test
```

## ğŸ“ Documentation

- [Backend API Documentation](./backend/README.md)
- [Frontend Documentation](./frontend/README.md)
- [API Reference](http://localhost:8000/docs) (when running)

## ğŸ¤ Contributing

This is a university project. For questions or suggestions, please contact team members.

## ğŸ“„ License

MIT License

## ğŸ¯ Deliverables

1. âœ… Working bias detection system
2. âœ… Interactive web interface
3. âœ… RESTful API
4. ğŸ”„ Trained classifier models (in progress)
5. ğŸ”„ Comprehensive analysis report (in progress)
6. ğŸ”„ Recorded presentation (pending)

## ğŸ“š References

- BEADs Dataset: [Hugging Face](https://huggingface.co/datasets/shainar/BEAD)
- StereoSet: [MIT Press](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00355/96428/StereoSet-Measuring-stereotypical-bias-in)
- Jigsaw Toxicity: [Kaggle](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)

## ğŸ“ Academic Context

**Institution:** University of Michigan - Dearborn  
**Course:** Computer Science Senior Project  
**Semester:** Fall 2025  
**Instructor:** [To be added]

---

**Built with â¤ï¸ by Team Bias Detectives**
